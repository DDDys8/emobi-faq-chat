import streamlit as st
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI

import os
openai_key = os.environ.get("OPENAI_API_KEY")

llm = ChatOpenAI(model_name="gpt-3.5-turbo", openai_api_key=openai_key)
qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=None)

st.title("ğŸš™ Emobi - ã‚ˆãã‚ã‚‹è³ªå•ãƒãƒ£ãƒƒãƒˆ")

query = st.text_input("çŸ¥ã‚ŠãŸã„ã“ã¨ã‚’èã„ã¦ãã ã•ã„", placeholder="ä¾‹ï¼šä¿é™ºã¯ã¤ã„ã¦ã¾ã™ã‹ï¼Ÿ")

if query:
    with st.spinner("èª¿ã¹ã¦ã„ã¾ã™..."):
        result = qa_chain.invoke({"query": query})
        answer = result.get("result", "å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    st.markdown(f"### âœ… å›ç­”\n{answer}")
