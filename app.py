import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI

# âœ… OpenAI APIã‚­ãƒ¼ã‚’ .streamlit/secrets.toml ã«è¨˜è¼‰ã—ã¦ãã ã•ã„
openai_key = st.secrets["OPENAI_API_KEY"]

# âœ… åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆè»½é‡ãƒ¢ãƒ‡ãƒ«ï¼†CPUå‹•ä½œï¼‰
embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# âœ… LLMï¼ˆOpenAI Chat APIï¼‰
llm = ChatOpenAI(model_name="gpt-3.5-turbo", openai_api_key=openai_key)

# âœ… ã‚ˆãã‚ã‚‹è³ªå•ã®ãƒšã‚¢ï¼ˆã“ã“ã‚’ç·¨é›†ï¼‰
faq_pairs = [
    "Q: åˆæœŸè²»ç”¨ã¯åˆè¨ˆã§ã„ãã‚‰ã‹ã‹ã‚‹ã®ã‹ï¼Ÿ\nA: å®Ÿè³ªè¼¸é€è²»ã¨ãªã‚Šã¾ã™ã€‚",
    "Q: ä¿é™ºã®å†…å®¹ã¯ã©ã†ãªã£ã¦ã„ã¾ã™ã‹ï¼Ÿ\nA: ä»»æ„ä¿é™ºã«åŠ å…¥æ¸ˆã§ã€å¯¾äººãƒ»å¯¾ç‰©ãƒ»æ­ä¹—è€…å…¨ã¦ã‚«ãƒãƒ¼ã•ã‚Œã¾ã™ã€‚",
    "Q: 1æ—¥ã®å¹³å‡ç¨¼åƒå›æ•°ã¯ï¼Ÿ\nA: å¹³æ—¥ã¯1å›è»¢ã€ä¼‘æ—¥ã¯2å›è»¢ãŒç›®å®‰ã§ã™ã€‚",
    "Q: ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ”¯æ´ã£ã¦æœ¬å½“ã«åŠ¹æœã‚ã‚‹ã®ï¼Ÿ\nA: SNSã‚’è»¸ã«å®Ÿç¸¾ãŒã‚ã‚Šã€é›†å®¢å¢—åŠ ã«è²¢çŒ®ã—ã¦ã„ã¾ã™ã€‚",
    "Q: æ•…éšœã‚„äº‹æ•…æ™‚ã®å¯¾å¿œã¯ã©ã†ãªã£ã¦ã„ã¾ã™ã‹ï¼Ÿ\nA: ã‚µãƒãƒ¼ãƒˆãƒãƒ¼ãƒ ãŒå–¶æ¥­æ™‚é–“å†…ã§å³æ™‚å¯¾å¿œã—ã¾ã™ã€‚"
]

# âœ… FAQãƒ‡ãƒ¼ã‚¿ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦FAISSã«æ ¼ç´
db = FAISS.from_texts(texts=faq_pairs, embedding=embedding_model)
retriever = db.as_retriever(search_kwargs={"k": 4})

# âœ… LangChainã®RetrievalQAãƒã‚§ãƒ¼ãƒ³
qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=retriever)

# âœ… Streamlit UIæ§‹ç¯‰
st.set_page_config(page_title="Emobiãƒãƒ£ãƒƒãƒˆ", page_icon="ğŸ¤–")
st.title("âœ… Emobi ãƒãƒ£ãƒƒãƒˆ - ã‚ˆãã‚ã‚‹ã”è³ªå•")

query = st.text_input("æ°—ã«ãªã‚‹ã“ã¨ã‚’è³ªå•ã—ã¦ã¿ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šä¿é™ºã¯ã©ã†ãªã£ã¦ã¾ã™ã‹ï¼Ÿï¼‰")

if query:
    with st.spinner("è€ƒãˆä¸­ã§ã™..."):
        result = qa_chain.invoke({"query": query})
        st.markdown("### ğŸ“Œ å›ç­”ï¼š\n" + result["result"])
